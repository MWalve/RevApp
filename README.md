# gutSync - Gut-Brain Health Tracker

A comprehensive health tracking application that helps users understand the connection between their diet, gut health, and mental wellbeing using AI-powered insights.

## ðŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        Frontend                              â”‚
â”‚  Next.js 14 + React + TypeScript + Tailwind CSS             â”‚
â”‚  Port: 3000                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚ HTTP
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    FastAPI Backend                           â”‚
â”‚  Python 3.11 + FastAPI + LangChain + Ollama                 â”‚
â”‚  Port: 8000                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  RAG System (Loaded Once at Startup)                â”‚   â”‚
â”‚  â”‚  â€¢ HuggingFace Embeddings                           â”‚   â”‚
â”‚  â”‚  â€¢ ChromaDB Vector Store                            â”‚   â”‚
â”‚  â”‚  â€¢ Ollama LLM (llama3.2)                            â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Supabase                                 â”‚
â”‚  PostgreSQL Database + Authentication                        â”‚
â”‚  â€¢ User Data â€¢ Mood Logs â€¢ Food Logs                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ðŸš€ Quick Start

### Prerequisites

- **Node.js 18+** and npm
- **Python 3.11+**
- **Ollama** (for local LLM)
- **Supabase** account (free tier)

### 1. Install Ollama

**Windows:**
```powershell
winget install Ollama.Ollama
```

**macOS/Linux:**
```bash
curl -fsSL https://ollama.com/install.sh | sh
```

Then pull a model:
```bash
ollama pull llama3.2
```

### 2. Backend Setup

```bash
# Navigate to backend
cd backend

# Create virtual environment
python -m venv venv

# Activate (Windows)
.\venv\Scripts\activate

# Activate (macOS/Linux)
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt

# Copy environment config
cp env.example .env

# Start Ollama (in separate terminal)
ollama serve

# Run backend
python main.py
```

Backend will be available at: http://localhost:8000

### 3. Frontend Setup

```bash
# Navigate to frontend
cd revapp-gba

# Install dependencies
npm install

# Create .env.local file
cat > .env.local << EOF
BACKEND_URL=http://localhost:8000
NEXT_PUBLIC_SUPABASE_URL=your_supabase_url
NEXT_PUBLIC_SUPABASE_ANON_KEY=your_supabase_key
NEXT_PUBLIC_USDA_API_KEY=your_usda_key
EOF

# Run development server
npm run dev
```

Frontend will be available at: http://localhost:3000

## ðŸ³ Docker Deployment

Run both services with Docker Compose:

```bash
# Start Ollama on host first
ollama serve

# Build and run containers
docker-compose up --build

# Or run in background
docker-compose up -d
```

Access:
- Frontend: http://localhost:3000
- Backend API: http://localhost:8000
- API Docs: http://localhost:8000/docs

## ðŸ“ Project Structure

```
RevApp/
â”œâ”€â”€ backend/                 # FastAPI Backend
â”‚   â”œâ”€â”€ main.py             # FastAPI app entry point
â”‚   â”œâ”€â”€ rag_system.py       # RAG with Ollama integration
â”‚   â”œâ”€â”€ models.py           # Pydantic request/response models
â”‚   â”œâ”€â”€ config.py           # Configuration management
â”‚   â”œâ”€â”€ requirements.txt    # Python dependencies
â”‚   â”œâ”€â”€ Dockerfile          # Backend container
â”‚   â””â”€â”€ README.md           # Backend documentation
â”‚
â”œâ”€â”€ revapp-gba/             # Next.js Frontend
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ app/            # Next.js 14 App Router
â”‚   â”‚   â”‚   â”œâ”€â”€ api/        # API routes
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ chat/   # RAG chat endpoint
â”‚   â”‚   â”‚   â”œâ”€â”€ chat/       # Chat page
â”‚   â”‚   â”‚   â”œâ”€â”€ dashboard/  # Analytics dashboard
â”‚   â”‚   â”‚   â””â”€â”€ ...
â”‚   â”‚   â”œâ”€â”€ components/     # React components
â”‚   â”‚   â””â”€â”€ lib/            # Utilities (Supabase client)
â”‚   â”œâ”€â”€ chroma_db/          # Vector database (gitignored)
â”‚   â”œâ”€â”€ foodAndMoodPaper.pdf # Research document
â”‚   â”œâ”€â”€ Dockerfile          # Frontend container
â”‚   â””â”€â”€ package.json
â”‚
â”œâ”€â”€ docker-compose.yml      # Orchestrate both services
â””â”€â”€ README.md               # This file
```

## ðŸ”§ Configuration

### Backend Configuration

Edit `backend/.env`:

```env
# LLM Provider
LLM_PROVIDER=ollama          # or "groq" for cloud API
OLLAMA_MODEL=llama3.2        # or "mistral", "phi3"

# RAG Settings
CHUNK_SIZE=1000
SIMILARITY_TOP_K=3

# Optional: Cloud LLM APIs
GROQ_API_KEY=your_key        # Get from console.groq.com
```

### Frontend Configuration

Edit `revapp-gba/.env.local`:

```env
BACKEND_URL=http://localhost:8000
NEXT_PUBLIC_SUPABASE_URL=https://xxx.supabase.co
NEXT_PUBLIC_SUPABASE_ANON_KEY=your_key
NEXT_PUBLIC_USDA_API_KEY=your_key
```

## ðŸŽ¯ Key Features

### Current Features
- âœ… **Mood Tracking**: Log mood with anxiety, energy, mental clarity, digestive comfort
- âœ… **Food Logging**: Search USDA food database and log meals
- âœ… **AI Chat**: Ask questions about gut-brain connection
- âœ… **History Views**: View past mood and food entries
- âœ… **Dashboard**: Visualize trends and correlations
- âœ… **RAG System**: Research-backed AI responses

### Performance Improvements
| Metric | Before (exec) | After (FastAPI) |
|--------|---------------|-----------------|
| First request | ~60s | ~10s (model load) |
| Subsequent requests | ~60s each | ~2-5s |
| Memory usage | 0MB (idle) | ~2GB (persistent) |

## ðŸ” Security Fixes

The new architecture addresses critical security issues:

- âœ… **No Command Injection**: Replaced shell exec with HTTP API
- âœ… **Input Validation**: Pydantic models validate all inputs
- âœ… **API Key Protection**: Backend handles external API calls
- ðŸš§ **Authentication**: Supabase Auth (TODO)
- ðŸš§ **Rate Limiting**: Add in production

## ðŸ§ª Development

### Run Tests

```bash
# Backend tests
cd backend
pytest

# Frontend tests
cd revapp-gba
npm test
```

### Code Quality

```bash
# Backend
black .
mypy .

# Frontend
npm run lint
```

## ðŸ“š API Documentation

Once the backend is running, visit:
- **Swagger UI**: http://localhost:8000/docs
- **ReDoc**: http://localhost:8000/redoc

### Example API Call

```bash
curl -X POST http://localhost:8000/query \
  -H "Content-Type: application/json" \
  -d '{
    "query": "How does sugar affect my mood?",
    "user_data": {
      "moods": [{"mood": 6, "date": "2024-01-02"}]
    }
  }'
```

## ðŸš€ Deployment

### Railway (Recommended)

```bash
# Install Railway CLI
npm i -g @railway/cli

# Login
railway login

# Deploy backend
cd backend
railway up

# Deploy frontend
cd ../revapp-gba
railway up
```

### Render / Fly.io

Both services include Dockerfiles for easy deployment to any container platform.

## ðŸ› ï¸ Troubleshooting

### Backend won't start
```bash
# Check Ollama is running
curl http://localhost:11434/api/tags

# Start Ollama if not running
ollama serve
```

### "Model not found"
```bash
ollama pull llama3.2
```

### Frontend can't connect to backend
```bash
# Check backend is running
curl http://localhost:8000/health

# Update BACKEND_URL in .env.local
```

## ðŸ“ Migration from Old Architecture

The old system used `child_process.exec()` to spawn Python on every request. The new system:

1. âœ… Runs Python as a persistent FastAPI server
2. âœ… Loads models once at startup
3. âœ… Uses HTTP instead of shell commands
4. âœ… Adds proper error handling and validation
5. âœ… Implements actual LLM generation (not just raw chunks)

## ðŸ¤ Contributing

1. Create a feature branch: `git checkout -b feature/my-feature`
2. Make changes and test thoroughly
3. Update documentation
4. Submit a pull request

## ðŸ“„ License

MIT License - see LICENSE file for details

## ðŸ”— Links

- [Next.js Documentation](https://nextjs.org/docs)
- [FastAPI Documentation](https://fastapi.tiangolo.com/)
- [Ollama Documentation](https://ollama.ai/docs)
- [LangChain Documentation](https://python.langchain.com/)
- [Supabase Documentation](https://supabase.com/docs)

## ðŸ’¡ Future Enhancements

- [ ] Streaming chat responses
- [ ] User authentication with Supabase Auth
- [ ] Push notifications for mood tracking
- [ ] Data export (CSV/PDF reports)
- [ ] Mobile app (React Native)
- [ ] Integration with wearables
- [ ] Advanced analytics and predictions
- [ ] Community features and insights sharing

---

**Built with â¤ï¸ for better gut-brain health**
